{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-large\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    response = requests.post(API_URL, headers=headers, data=data)\n",
    "    return response.json()\n",
    "\n",
    "output = query(\"C:/Users/shrey/OneDrive/Desktop/EthMumbai/artifacts/WhatsApp Image 2024-03-30 at 23.55.54_61b8d6ba.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': 'people sitting at tables in a large room with a ceiling'}\n"
     ]
    }
   ],
   "source": [
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    image = request.files[\"image\"]\n",
    "    image.save(\"C:/Users/shrey/OneDrive/Desktop/EthMumbai/artifacts/image1.jpg\")\n",
    "\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-large\"\n",
    "    headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "    def query(filename):\n",
    "        with open(filename, \"rb\") as f:\n",
    "            data = f.read()\n",
    "        response = requests.post(API_URL, headers=headers, data=data)\n",
    "        return response.json()\n",
    "\n",
    "    output = query(\"C:/Users/shrey/OneDrive/Desktop/EthMumbai/artifacts/image1.jpg\")\n",
    "    print(output[0][\"generated_text\"])\n",
    "\n",
    "    genai.configure(api_key=\"AIzaSyBa5b8ZuK83ehPi52ua4Ly724ofJHTT5Zk\")\n",
    "    model = genai.GenerativeModel(\"gemini-pro\")\n",
    "    # Here is my description in 5-10 words only write hinglish texts all text in english letter on\n",
    "    response = model.generate_content(\n",
    "        f\"Write a funny meme caption in 7-10 words, in the style of popular Indian internet humor, based on the following description:{output[0]['generated_text']}\"\n",
    "    )\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can't touch this :ceiling:\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "\n",
    "# API_URL = \"https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-large\"\n",
    "# headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "# def query(filename):\n",
    "#     with open(filename, \"rb\") as f:\n",
    "#         data = f.read()\n",
    "#     response = requests.post(API_URL, headers=headers, data=data)\n",
    "#     return response.json()\n",
    "\n",
    "# output = query(\"C:/Users/shrey/OneDrive/Pictures/IMG_7355.JPG\")\n",
    "\n",
    "# Used to securely store your API key\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "genai.configure(api_key='AIzaSyBa5b8ZuK83ehPi52ua4Ly724ofJHTT5Zk')\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "response = model.generate_content(f\"You are a Indian meme expert, you can generate short sarcastic meme captions from descriptions. Here is my description:'''{output[0]['generated_text']}'''\")\n",
    "print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(\"C:/Users/shrey/OneDrive/Desktop/EthMumbai/artifacts/WhatsApp Image 2024-03-30 at 23.55.54_61b8d6ba.jpg\")\n",
    "\n",
    "# Define text to be drawn\n",
    "text = response.text\n",
    "\n",
    "# Calculate font scale based on image width\n",
    "font_scale = image.shape[1] / 1000  # Adjust divisor as needed\n",
    "\n",
    "# Choose font\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# Determine text size\n",
    "text_size, _ = cv2.getTextSize(text, font, font_scale, thickness=2)\n",
    "\n",
    "# Calculate text position (centered at the top)\n",
    "text_x = (image.shape[1] - text_size[0]) // 2\n",
    "text_y = text_size[1] + 50  # Adjust the value to position the text\n",
    "\n",
    "# Add white outline to the text\n",
    "cv2.putText(image, text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "# Add white font to the text (thinner)\n",
    "cv2.putText(image, text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness=3, lineType=cv2.LINE_AA)\n",
    "\n",
    "# Save the image with the text\n",
    "cv2.imwrite(\"output.png\", image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(\"C:/Users/shrey/OneDrive/Desktop/EthMumbai/artifacts/WhatsApp Image 2024-03-30 at 23.55.54_61b8d6ba.jpg\")\n",
    "\n",
    "# Define text to be drawn\n",
    "text = response.text\n",
    "\n",
    "# Calculate font scale based on image width\n",
    "font_scale = image.shape[1] / 800  # Adjust divisor as needed for a larger text size\n",
    "\n",
    "# Choose font\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# Determine text size\n",
    "text_size, _ = cv2.getTextSize(text, font, font_scale, thickness=2)\n",
    "\n",
    "# Calculate text position (centered at the top)\n",
    "text_x = (image.shape[1] - text_size[0]) // 2\n",
    "text_y = text_size[1] + 50  # Adjust the value to position the text\n",
    "\n",
    "# Add drop shadow effect (black outline)\n",
    "shadow_offset = 2\n",
    "cv2.putText(image, text, (text_x + shadow_offset, text_y + shadow_offset), font, font_scale, (0, 0, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "# Add white font to the text\n",
    "cv2.putText(image, text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "# Save the image with the text\n",
    "cv2.imwrite(\"output.png\", image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You can't touch this :ceiling:\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(\"C:/Users/shrey/OneDrive/Desktop/EthMumbai/artifacts/WhatsApp Image 2024-03-30 at 23.55.54_61b8d6ba.jpg\")\n",
    "\n",
    "# Define text to be drawn\n",
    "text = response.text\n",
    "\n",
    "# Choose font scale and thickness\n",
    "font_scale = 5  # Increase the font scale for larger text\n",
    "outline_thickness = 50  # Thickness for the black outline\n",
    "font_thickness = 5\n",
    "\n",
    "# Choose text color in BGR format (here, white for the font)\n",
    "text_color = (255, 255, 255)\n",
    "\n",
    "# Choose text color in BGR format (here, black for the outline)\n",
    "outline_color = (0, 0, 0)\n",
    "\n",
    "# Load font (provide the path to your font file)\n",
    "font_path = \"path/to/ant1.ttf\"  # Replace with the actual path to your font file\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# Determine text size\n",
    "text_size, _ = cv2.getTextSize(text, font, font_scale, outline_thickness)\n",
    "\n",
    "# Calculate text position (centered at the top)\n",
    "text_x = (image.shape[1] - text_size[0]) // 2\n",
    "text_y = text_size[1] + 50  # Adjust the value to position the text\n",
    "\n",
    "# Add black outline to the text\n",
    "cv2.putText(image, text, (text_x, text_y), font, font_scale, outline_color, thickness=outline_thickness)\n",
    "\n",
    "# Add white font to the text\n",
    "cv2.putText(image, text, (text_x, text_y), font, font_scale, text_color, thickness=font_thickness)\n",
    "\n",
    "# Save the image with the text\n",
    "cv2.imwrite(\"output.png\", image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IT Crowd: Laptop squad assemble!\n"
     ]
    }
   ],
   "source": [
    "# Used to securely store your API key\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "genai.configure(api_key='AIzaSyBa5b8ZuK83ehPi52ua4Ly724ofJHTT5Zk')\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "response = model.generate_content(f\"this is the description for photo '''{output[0]['generated_text']}''' write a 5- 10 word meme for it humor should be very nice\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = request.files[\"image\"]\n",
    "image_file = image.read()\n",
    "image_size = 350\n",
    "image = load_demo_image(image_file, image_size=image_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageDraw' object has no attribute 'textsize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m font \u001b[38;5;241m=\u001b[39m ImageFont\u001b[38;5;241m.\u001b[39mtruetype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marial.ttf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m36\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Determine text size\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m text_width, text_height \u001b[38;5;241m=\u001b[39m draw\u001b[38;5;241m.\u001b[39mtextsize(text, font\u001b[38;5;241m=\u001b[39mfont)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Calculate text position (centered)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m image_width, image_height \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39msize\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ImageDraw' object has no attribute 'textsize'"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Load the image\n",
    "image = Image.open(\"C:/Users/shrey/OneDrive/Pictures/IMG_7355.JPG\")\n",
    "\n",
    "# Initialize the drawing context\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Define text to be drawn\n",
    "text = \"Sample Text\"\n",
    "\n",
    "# Choose a font (adjust the path to your font file as necessary)\n",
    "font = ImageFont.truetype(\"arial.ttf\", 36)\n",
    "\n",
    "# Determine text size\n",
    "text_width, text_height = draw.textsize(text, font=font)\n",
    "\n",
    "# Calculate text position (centered)\n",
    "image_width, image_height = image.size\n",
    "text_x = (image_width - text_width) // 2\n",
    "text_y = (image_height - text_height) // 2\n",
    "\n",
    "# Set text color\n",
    "text_color = (255, 255, 255)  # White\n",
    "\n",
    "# Draw text on image\n",
    "draw.text((text_x, text_y), text, fill=text_color, font=font)\n",
    "\n",
    "# Save or display the image\n",
    "image.save(\"output.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.174.47:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "from flask_cors import CORS\n",
    "import io\n",
    "import json\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "from flask import Flask, request, send_file\n",
    "import os\n",
    "import uuid\n",
    "import datetime\n",
    "\n",
    "\n",
    "from PIL import ImageFont\n",
    "\n",
    "# Use a default font provided by PIL\n",
    "font = ImageFont.load_default()\n",
    "\n",
    "# Alternatively, you can specify the font size\n",
    "font_with_size = ImageFont.load_default().font_variant(size=12)\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "@app.route(\"/\")\n",
    "def hello_world():\n",
    "    a = \"Welcome!\"\n",
    "    return a\n",
    "\n",
    "\n",
    "@app.route(\"/upload\", methods=[\"POST\"])\n",
    "def upload():\n",
    "    # Third-party API\n",
    "    image = request.files[\"image\"]\n",
    "    image_file = image.read()\n",
    "    image_size = 350\n",
    "    image = load_demo_image(image_file, image_size=image_size, device=device)\n",
    "    image.save(\"image.jpg\")\n",
    "\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     # Beam search\n",
    "    #     # caption = model.generate(image, sample=False, num_beams=9, max_length=20, min_length=5)\n",
    "    #     # Nucleus sampling\n",
    "    #     caption = model.generate(\n",
    "    #         image, sample=True, top_p=0.9, max_length=20, min_length=5\n",
    "    #     )\n",
    "    #     print(\"caption: \" + caption[0])\n",
    "    # text = caption[0]\n",
    "    import requests\n",
    "\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-large\"\n",
    "    headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "    def query(filename):\n",
    "        with open(filename, \"rb\") as f:\n",
    "            data = f.read()\n",
    "        response = requests.post(API_URL, headers=headers, data=data)\n",
    "        return response.json()\n",
    "\n",
    "    output = query(\"image.jpg\")\n",
    "\n",
    "    # Used to securely store your API key\n",
    "    import google.generativeai as genai\n",
    "\n",
    "    # Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "    genai.configure(api_key='AIzaSyBa5b8ZuK83ehPi52ua4Ly724ofJHTT5Zk')\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "    response = model.generate_content(f\"this is the description for photo '''{output[0]['generated_text']}''' write a 5- 10 word meme for it humor should be very nice\")\n",
    "    print(response.text)\n",
    "    # print(generated_text)\n",
    "\n",
    "    # Example usage\n",
    "    n = ImgText(response.text, image_file)\n",
    "    res = n.draw_text()\n",
    "    json_data = {\n",
    "        \"data\": \"https://nginx-web-fraork-njcq-uwcqowzevm.cn-chengdu.fcapp.run\" + res\n",
    "    }\n",
    "    json_img = json.dumps(json_data)\n",
    "    print(json_img)\n",
    "    return json_img\n",
    "\n",
    "\n",
    "def load_demo_image(image_file, image_size, device):\n",
    "    # Convert image to PIL Image object\n",
    "    image = Image.open(io.BytesIO(image_file))\n",
    "    # Convert image to RGB format\n",
    "    raw_image = image.convert(\"RGB\")\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(\n",
    "                (image_size, image_size), interpolation=InterpolationMode.BICUBIC\n",
    "            ),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                (0.48145466, 0.4578275, 0.40821073),\n",
    "                (0.26862954, 0.26130258, 0.27577711),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    image = transform(raw_image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Print tensor shape for debugging\n",
    "    print(f\"Image tensor shape: {image.shape}\")\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "class ImgText:\n",
    "    font = ImageFont.truetype(\"kuaikanshijieti.ttf\", 50)\n",
    "\n",
    "    def __init__(self, text, image):\n",
    "        img = Image.open(io.BytesIO(image))\n",
    "        width = img.size[0]\n",
    "        height = img.size[1]\n",
    "        print(width)\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.text = text\n",
    "        self.image = image\n",
    "        self.duanluo, self.note_height, self.line_height = self.split_text()\n",
    "\n",
    "    def get_paragraph(self, text):\n",
    "        txt = Image.new(\"RGBA\", (100, 100), (255, 255, 255, 0))\n",
    "        draw = ImageDraw.Draw(txt)\n",
    "        paragraphs = \"\"\n",
    "        total_width = 0\n",
    "        line_count = 1\n",
    "        line_height = 0\n",
    "        for char in text:\n",
    "            bbox = draw.textbbox((0, 0), char, font=ImgText.font)\n",
    "            width = bbox[2] - bbox[0]\n",
    "            height = bbox[3] - bbox[1]\n",
    "            total_width += width\n",
    "            if total_width > self.width:\n",
    "                line_count += 1\n",
    "                total_width = 0\n",
    "                paragraphs += \"/n\"\n",
    "            paragraphs += char\n",
    "            line_height = max(height, line_height)\n",
    "        if not paragraphs.endswith(\"/n\"):\n",
    "            paragraphs += \"/n\"\n",
    "        return paragraphs, line_height, line_count\n",
    "\n",
    "    def split_text(self):\n",
    "        max_line_height, total_lines = 0, 0\n",
    "        allText = []\n",
    "        for text in self.text.split(\"/n\"):\n",
    "            paragraph, line_height, line_count = self.get_paragraph(text)\n",
    "            max_line_height = max(line_height, max_line_height)\n",
    "            total_lines += line_count\n",
    "            allText.append((paragraph, line_count))\n",
    "        line_height = max_line_height\n",
    "        total_height = total_lines * line_height\n",
    "        return allText, total_height, line_height\n",
    "\n",
    "    def draw_text(self):\n",
    "        note_img = Image.open(io.BytesIO(self.image)).convert(\"RGB\")\n",
    "        draw = ImageDraw.Draw(note_img)\n",
    "        x, y = 0, int(self.height) / 2\n",
    "        for paragraph, line_count in self.duanluo:\n",
    "            draw.text((x + 2, y), paragraph, fill=(0, 0, 0), font=ImgText.font)\n",
    "            draw.text((x - 2, y), paragraph, fill=(255, 255, 255), font=ImgText.font)\n",
    "            draw.text((x, y + 2), paragraph, fill=(0, 0, 0), font=ImgText.font)\n",
    "            draw.text((x, y - 2), paragraph, fill=(255, 255, 255), font=ImgText.font)\n",
    "            y += self.line_height * line_count\n",
    "\n",
    "        today = datetime.date.today()\n",
    "\n",
    "        dir_name = today.strftime(\"%Y-%m-%d\")\n",
    "        dir_path = os.path.join(\"/home/BLIP/imagedir\", dir_name)\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.mkdir(dir_path)\n",
    "        else:\n",
    "            print(\"Directory already exists, skipping creation\")\n",
    "\n",
    "        filename = str(uuid.uuid4()) + \".jpg\"\n",
    "        note_img.save(\"./imagedir/\" + dir_name + \"/\" + filename)\n",
    "        os.chmod(\"./imagedir/\" + dir_name + \"/\" + filename, 0o777)\n",
    "        return \"/imagedir/\" + dir_name + \"/\" + filename\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def callu(number):\n",
    "        headers = {\n",
    "        'Authorization': \"sk-49l0jhdx24371l57ronsc74no6o2py5ghoa6wkczwcu7xd6z6kd99lwyk3nn6hvx69\"\n",
    "        }\n",
    "\n",
    "        # Data\n",
    "        data = {\n",
    "        'phone_number': \"+91\"+ number,\n",
    "        'task': \"\"\"Fantastic! To begin your crowdfunding campaign, head to the 'Campaigns' section and follow the prompts to create your campaign page. Should you have any specific questions or need assistance, feel free to ask, and I'll be here to help.\"\n",
    "\n",
    "**Regarding participation in crowdfunding campaigns, our platform typically allows all users to participate, provided they meet certain criteria, such as compliance with our community guidelines and any legal requirements applicable to crowdfunding activities. However, it's always a good idea to review the specific terms and conditions associated with each campaign to ensure eligibility and compliance.\"\n",
    "\n",
    "User: \"Thank you for your assistance. I'll start setting up my campaign now.\"\n",
    "\"I appreciate your help. I'll reach out if I have any further questions.\"\n",
    "\"I'm impressed with the features. I'll definitely recommend this app to others.\"\n",
    "\n",
    "AI:\n",
    "\"Great to hear! If you have any further questions or need assistance in the future, don't hesitate to reach out. We're here to support you every step of the way. Thank you for choosing Dsocial's decentralized social network app, leveraging blockchain technology for secure and transparent transactions. Have a wonderful day!\n",
    "\n",
    "User: \"How secure are P2P transfers on this app? Is my financial information safe?\"\n",
    "AI: \"Security is a top priority for us. Our platform utilizes advanced encryption and security measures to ensure the safety of your financial information during P2P transfers. Additionally, we adhere to strict privacy policies to protect your personal data.\"\n",
    "\n",
    "Customer Support:\n",
    "User: \"What should I do if I encounter an issue while using the app?\"\n",
    "AI: \"If you encounter any issues or have questions while using our app, you can reach out to our dedicated customer support team for assistance. We offer various support channels, including live chat, email, and a help center, to ensure that your concerns are addressed promptly.\"\n",
    "\n",
    "Integration with External Wallets:\n",
    "User: \"Can I link my external cryptocurrency wallet to this app for P2P transfers?\"\n",
    "AI: \"At the moment, our platform supports internal wallet transactions for P2P transfers. However, we're continuously exploring options for integrating external wallets to provide more flexibility for our users. Stay tuned for any updates on this feature!\"\n",
    "\n",
    "Rewards and Loyalty Programs:\n",
    "User: \"Does the app offer any rewards or loyalty programs for frequent users?\"\n",
    "AI: \"Yes, we value our users' loyalty and engagement. We have plans to introduce rewards and loyalty programs in the near future, offering incentives for active participation and contributions within our community. Keep an eye out for announcements about these programs!\"\n",
    "\n",
    "Future Development Roadmap:\n",
    "User: \"What new features or updates can we expect from the app in the future?\"\n",
    "AI: \"We're committed to continuous improvement and innovation. Our development team is working on several exciting features and updates, including enhanced social networking capabilities, expanded payment options, and integration with decentralized finance (DeFi) protocols. We'll keep our users informed about upcoming releases and developments.\"\"\",\n",
    "        'voice_id': 1,\n",
    "        'reduce_latency': True,\n",
    "        'request_data': {},\n",
    "        'voice_settings':{\n",
    "            \"speed\": \"0.8\"\n",
    "        },\n",
    "        'interruption_threshold': 0,\n",
    "        'start_time': None,\n",
    "        'transfer_phone_number': None,\n",
    "        'answered_by_enabled': False,\n",
    "        'from': None,\n",
    "        'first_sentence': None,\n",
    "        'record': True,\n",
    "        'max_duration': 2,\n",
    "        'model': 'enhanced',\n",
    "        'language': 'ENG',\n",
    "        }\n",
    "\n",
    "        # API request \n",
    "        requests.post('https://api.bland.ai/call', json=data, headers=headers)   \n",
    "        \n",
    "        return \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callu(\"9874233126\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.getimg.ai/v1/latent-consistency/text-to-image\"\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"content-type\": \"application/json\",\n",
    "    \"authorization\": \"Bearer key-1eJ6PrczMvKQmJVeMGr1y8p37CULdDSBAOnesUawLPqVAnE8cg8uxBl93RgLuus72xATfy7IGAiUs62gSd2QBmTwhekRiFdl\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response[\"data\"][\"image_url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyBa5b8ZuK83ehPi52ua4Ly724ofJHTT5Zk\")\n",
    "model = genai.GenerativeModel(\"gemini-pro\")\n",
    "\n",
    "\n",
    "response = model.generate_content(\n",
    "                f\"Context provided by the user, write a hilarious meme caption in 7-10 words, in the style of popular memers, meme should be relevent to anime community.\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.generativeai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerativeai\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgenai\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_json_response\u001b[39m(prompt):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.generativeai'"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "\n",
    "def get_json_response(prompt):\n",
    "    genai.configure(api_key=\"AIzaSyBa5b8ZuK83ehPi52ua4Ly724ofJHTT5Zk\")\n",
    "    model = genai.GenerativeModel(\"gemini-pro\")\n",
    "    \n",
    "    response = model.generate_content(prompt)\n",
    "    \n",
    "    # Create a dictionary to hold the JSON response\n",
    "    json_response = {\n",
    "        \"prompt\": prompt,\n",
    "        \"generated_content\": response\n",
    "    }\n",
    "    \n",
    "    return json_response\n",
    "\n",
    "# Example usage\n",
    "prompt = \"Context provided by the user: Meme on Modi, write a hilarious meme caption in 7-10 words, in the style of popular memers, Generate a JSON response as follows: {'meme_caption': 'caption','meme_image_description':'image_describtion'}, make sure the string u are returning it should be convertable to dict object in python. and grammtically correct.\"\n",
    "json_response = get_json_response(prompt)\n",
    "result = json_response[\"generated_content\"].text\n",
    "\n",
    "# result = \"{'meme_caption': 'When you realize your crush is just as awkward as you', 'meme_image_description': ''}\"\n",
    "\n",
    "# Clean the response and ensure it is a valid JSON string\n",
    "result = result.strip().replace('```json', \"\").replace('```', \"\").replace(\"\\\"\", \"\").replace('\"', \"\").replace(\"'\", \"'\").strip()\n",
    "result = result.replace(\"'\", \"\\\"\")\n",
    "\n",
    "\n",
    "try:\n",
    "    json_data = json.loads(result)\n",
    "    data = {\n",
    "    \"Meme Caption\": json_data[\"meme_caption\"],\n",
    "    \"Meme Image Description\": json_data[\"meme_image_description\"]\n",
    "    }\n",
    "    print(data)\n",
    "    print(json_data)\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(\"Failed to decode JSON:\", e)\n",
    "    print(\"Raw response:\", result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('{\"meme_caption\": \"Modiji ne bola tha 15 lakh aayenge, ab tak to sirf jumle hi aaye\", \"meme_image_description\": \"A photo of Modi with a text overlay that says, Modi promised 15 lakhs, but all we got are jumlas (empty promises).}',\n",
       " {'prompt': \"Context provided by the user: Meme on Modi, write a hilarious meme caption in 7-10 words, in the style of popular memers, Generate a JSON response as follows: {'meme_caption': 'caption','meme_image_description':'image_describtion'}, make sure the string u are returning it should be convertable to dict object in python. and grammtically correct.\",\n",
       "  'generated_content': response:\n",
       "  GenerateContentResponse(\n",
       "      done=True,\n",
       "      iterator=None,\n",
       "      result=glm.GenerateContentResponse({'candidates': [{'content': {'parts': [{'text': '{\\'meme_caption\\': \\'Modiji ne bola tha 15 lakh aayenge, ab tak to sirf jumle hi aaye\\', \\'meme_image_description\\': \\'A photo of Modi with a text overlay that says, \"Modi promised 15 lakhs, but all we got are jumlas (empty promises).\"}'}], 'role': 'model'}, 'finish_reason': 1, 'index': 0, 'safety_ratings': [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 2, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}], 'token_count': 0, 'grounding_attributions': []}]}),\n",
       "  )})"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('{\\n  \"meme_caption\": \"When the teacher asks a question and you know the answer but don\"t want to seem like a nerd\",\\n  \"meme_image_description\": \"\"\\n}',\n",
       " {'meme_caption': 'Me trying to explain my logic to my cat',\n",
       "  'meme_image_description': 'A photo of a cat looking confused while a human is talking to it'})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_response = get_json_response(prompt)\n",
    "# result = json_response[\"generated_content\"].text\n",
    "# result = result.replace('```json', \"\")\n",
    "# result = result.replace('```', \"\")\n",
    "# data_string  = result.replace('\\n', \"\")\n",
    "# data_string  = result.replace('\"', \"\")\n",
    "# data_string  = result.replace('*', \"\")\n",
    "\n",
    "# print(data_string)\n",
    "\n",
    "# import json\n",
    "\n",
    "# # Parse the JSON data\n",
    "# json_data = json.loads(data_string)\n",
    "\n",
    "# json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m json_data\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json_data' is not defined"
     ]
    }
   ],
   "source": [
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting ',' delimiter: line 1 column 41 (char 40)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m data_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeme_caption\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen you realize Modi\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms beard is just a filter\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeme_image_description\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA photo of Modi with a surprised expression, revealing that his beard is fake.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Parse the JSON data\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m json_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(data_string)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Accessing the JSON data\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeme Caption:\u001b[39m\u001b[38;5;124m\"\u001b[39m, json_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeme_caption\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\shrey\\anaconda3\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_decoder\u001b[38;5;241m.\u001b[39mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\shrey\\anaconda3\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_decode(s, idx\u001b[38;5;241m=\u001b[39m_w(s, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mend())\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\shrey\\anaconda3\\Lib\\json\\decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting ',' delimiter: line 1 column 41 (char 40)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Given string containing JSON data\n",
    "data_string = '{\"meme_caption\": \"When you realize Modi\"s beard is just a filter\", \"meme_image_description\": \"A photo of Modi with a surprised expression, revealing that his beard is fake.\"}'\n",
    "# Parse the JSON data\n",
    "json_data = json.loads(data_string)\n",
    "\n",
    "# Accessing the JSON data\n",
    "print(\"Meme Caption:\", json_data[\"meme_caption\"])\n",
    "print(\"Meme Image Description:\", json_data[\"meme_image_description\"])\n",
    "\n",
    "data = {\n",
    "    \"Meme Caption:\", json_data[\"meme_caption\"],\n",
    "    \"Meme Image Description:\", json_data[\"meme_image_description\"]\n",
    "}\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Virat Kohli is depicted hitting a cover drive shot, but with a comical twist, such as wearing a clown\\'s nose or holding a giant spoon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': \"Context provided by the user: Meme on tik tok, write a hilarious meme caption in 7-10 words, in the style of popular memers, Generate a JSON response as follows: 'meme_caption': 'Your caption here','meme_image_description':'', make sure the string u are returning it should be convertable to dict object in python. \",\n",
       " 'generated_content': response:\n",
       " GenerateContentResponse(\n",
       "     done=True,\n",
       "     iterator=None,\n",
       "     result=glm.GenerateContentResponse({'candidates': [{'content': {'parts': [{'text': '```json\\n{\\n  \"meme_caption\": \"When the teacher asks a question and you know the answer but don\\'t want to seem like a nerd\",\\n  \"meme_image_description\": \"\"\\n}\\n```'}], 'role': 'model'}, 'finish_reason': 1, 'index': 0, 'safety_ratings': [{'category': 9, 'probability': 1, 'blocked': False}, {'category': 8, 'probability': 1, 'blocked': False}, {'category': 7, 'probability': 2, 'blocked': False}, {'category': 10, 'probability': 1, 'blocked': False}], 'token_count': 0, 'grounding_attributions': []}]}),\n",
       " )}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"meme_caption\": \"When the teacher asks a question and you know the answer but don\\'t want to seem like a nerd\",\\n  \"meme_image_description\": \"\"\\n}\\n```'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response[\"generated_content\"].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.generativeai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerativeai\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgenai\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_json_response\u001b[39m(prompt):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.generativeai'"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "\n",
    "def get_json_response(prompt):\n",
    "    genai.configure(api_key=\"AIzaSyBa5b8ZuK83ehPi52ua4Ly724ofJHTT5Zk\")\n",
    "    model = genai.GenerativeModel(\"gemini-pro\")\n",
    "    \n",
    "    response = model.generate_content(prompt)\n",
    "    \n",
    "    # Extract JSON content from the response\n",
    "    json_response = {\n",
    "        \"prompt\": prompt,\n",
    "        \"generated_content\": extract_json_content(response)\n",
    "    }\n",
    "    \n",
    "    return json_response\n",
    "\n",
    "def extract_json_content(response):\n",
    "    # Check if response is done and contains candidates\n",
    "    if response.done and response.result and response.result.candidates:\n",
    "        # Extract JSON content from the first candidate\n",
    "        first_candidate = response.result.candidates[0]\n",
    "        if 'content' in first_candidate and 'parts' in first_candidate['content']:\n",
    "            parts = first_candidate['content']['parts']\n",
    "            for part in parts:\n",
    "                if 'text' in part:\n",
    "                    try:\n",
    "                        # Attempt to parse text as JSON\n",
    "                        json_content = json.loads(part['text'])\n",
    "                        return json_content\n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "    \n",
    "    # Return None if JSON content is not found\n",
    "    return None\n",
    "\n",
    "\n",
    "# Example usage\n",
    "prompt = \"Context provided by the user: Virat Kholi meme , write a hilarious meme caption in 7-10 words, in the style of popular memers, Generate a JSON response as follows: 'meme_caption': 'Your caption here','meme_image_description':''\"\n",
    "json_response = get_json_response(prompt)\n",
    "# print(json.dumps(json_response, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x00000221D09753A0>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m---> 16\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(image_bytes))\n\u001b[0;32m     17\u001b[0m image\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage1.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m image\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\shrey\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3309\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3307\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[0;32m   3308\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[1;32m-> 3309\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x00000221D09753A0>"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/ehristoforu/dalle-3-xl-v2\"\n",
    "headers = {\n",
    "            \"Authorization\": \"Bearer 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\"\n",
    "}\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.content\n",
    "\n",
    "\n",
    "image_bytes = query({\"inputs\": \"DHONI with virat kholi in a match\"})\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "image = Image.open(io.BytesIO(image_bytes))\n",
    "image.save(\"image1.jpg\")\n",
    "image.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Failed to get a valid response. Status code: 503, Response: {\"error\":\"Model fluently/Fluently-XL-Final is currently loading\",\"estimated_time\":555.0420532226562}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to get a valid response. Status code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m image_bytes \u001b[38;5;241m=\u001b[39m query({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNigga chad\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Inspect the first few bytes to check if it's an image\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(image_bytes[:\u001b[38;5;241m100\u001b[39m])  \u001b[38;5;66;03m# Print the first 100 bytes for inspection\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 13\u001b[0m, in \u001b[0;36mquery\u001b[1;34m(payload)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to get a valid response. Status code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: Failed to get a valid response. Status code: 503, Response: {\"error\":\"Model fluently/Fluently-XL-Final is currently loading\",\"estimated_time\":555.0420532226562}"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/fluently/Fluently-XL-Final\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(payload):\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        return response.content\n",
    "    else:\n",
    "        raise Exception(f\"Failed to get a valid response. Status code: {response.status_code}, Response: {response.text}\")\n",
    "\n",
    "\n",
    "image_bytes = query({\"inputs\": \"Nigga chad\"})\n",
    "    # Inspect the first few bytes to check if it's an image\n",
    "print(image_bytes[:100])  # Print the first 100 bytes for inspection\n",
    "# Check content type (assumes the API returns an appropriate content type header)\n",
    "\n",
    "\n",
    "image = Image.open(io.BytesIO(image_bytes))\n",
    "image.save(\"image1.jpg\")\n",
    "image.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
